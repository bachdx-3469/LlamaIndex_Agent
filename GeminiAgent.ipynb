{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d7310c-3190-4ff5-86ad-60688c2665e0",
   "metadata": {},
   "source": [
    "# ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d6c808-9a84-4d8c-b42d-865df18a82b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Code\\Miniconda\\conda\\envs\\torch2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from llama_index.core.utils import print_text\n",
    "from dotenv import load_dotenv\n",
    "from src.core.utils.settings import load_settings\n",
    "\n",
    "load_dotenv(\"local.env\")\n",
    "settings = load_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef121cf1-93b7-45b1-9085-75d7feb915f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ddf2836-f39e-49b7-88fc-2aa50126bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.modules.models import GoogleLLM, GoogleEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "emb_model = GoogleEmbedding(api_key=settings.google_ai.api_key)\n",
    "llm = GoogleLLM(api_key=settings.google_ai.api_key)\n",
    "Settings.embed_model = emb_model\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8324a2f-433a-4de9-b483-4841fcb4a5dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05954554-5f2b-469b-a46d-28f16c1d03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is Japanese singer Yuuri?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5721e9-0661-4c92-91ac-6202445f3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.predict(query)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d7358-8d0f-4ea7-9ea9-2338dbb9325d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c50be7-5062-4b67-b08b-32adaec4b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d378fd-e545-4f77-9a58-5367336a1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare documents\n",
    "documents = SimpleDirectoryReader(input_dir=\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dbef64-6501-497a-b847-f66430b161c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "# Save index to disk\n",
    "index.storage_context.persist(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb8c6e-cc6f-474a-8ef7-540769b2f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828cd0d-ba9b-40db-874e-62639c83119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"index\")\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb8e2a-8f6d-4aa9-a3e5-becbed43c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.modules.response_synthesizers import google_response_synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c5d30-c946-4ee7-aa67-fb559d725394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query engine\n",
    "query_engine = index.as_query_engine(\n",
    "    response_synthesizer=google_response_synthesizer(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8e5ba-1319-4de6-afd4-e59310bd3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is Japanese singer Yuuri?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077e008-dd81-4f14-a779-54eead816507",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(query)\n",
    "pprint(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a96d95-2087-4874-b1b6-d7ae71e32e03",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4321da8-1382-4a1d-907c-8a829f3bebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from llama_index.core.tools import FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b35f7191-3cae-4dd0-86c0-d351ceb273ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools\n",
    "def search_info_from_wikipedia(prompt: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Do a wikipedia search for provided `prompt`\n",
    "    Returns a list of ten wikipedia titles that matches the prompt\n",
    "    \"\"\"\n",
    "    return wikipedia.search(prompt)\n",
    "\n",
    "\n",
    "def get_wikipedia_content_from_title(title: str) -> str:\n",
    "    \"\"\" Functions returns content of wikipedia page based on provided title \"\"\"\n",
    "    page = wikipedia.page(title)\n",
    "    return page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f8ca4d-9b24-4dcf-85f5-d05b19f3d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = FunctionTool.from_defaults(fn=search_info_from_wikipedia)\n",
    "content_tool = FunctionTool.from_defaults(fn=get_wikipedia_content_from_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b741f57-1aef-4f47-bca0-aca243179367",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = GoogleLLM(\n",
    "    api_key=settings.google_ai.api_key,\n",
    "    is_chat_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a29553-d24f-4ba8-b1c2-b639ae6b8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.modules.agents import GeminiReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6d667d6-dc39-47a6-a856-b5c669344139",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = GeminiReAct.from_tools([search_tool, content_tool], llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bda325db-24a5-49ce-8b07-6008febf0d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;32m> Prompt input to the LLM: \n",
      "\u001b[0m\u001b[1;3;32mRole: user\n",
      "Content: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: search_info_from_wikipedia\n",
      "Tool Description: search_info_from_wikipedia(prompt: str) -> list[str]\n",
      "\n",
      "    Do a wikipedia search for provided `prompt`\n",
      "    Returns a list of ten wikipedia titles that matches the prompt\n",
      "    \n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"prompt\": {\"title\": \"Prompt\", \"type\": \"string\"}}, \"required\": [\"prompt\"]}\n",
      "\n",
      "> Tool Name: get_wikipedia_content_from_title\n",
      "Tool Description: get_wikipedia_content_from_title(title: str) -> str\n",
      " Functions returns content of wikipedia page based on provided title \n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"title\": {\"title\": \"Title\", \"type\": \"string\"}}, \"required\": [\"title\"]}\n",
      "\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of search_info_from_wikipedia, get_wikipedia_content_from_title) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "Role: user\n",
      "Content: **Who is the Japanese singer Yuuri?\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The current language of the user is: english. I need to use a tool to help me answer the question.\n",
      "Action: search_info_from_wikipedia\n",
      "Action Input: {'prompt': 'Japanese singer Yuuri'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: ['Yuuri (singer-songwriter)', 'Yuri (Japanese name)', 'List of Japanese singers', 'Yuuri Morishita', 'Ayane (singer)', 'Bansanka', 'Japanese people in South Korea', 'The First Take', \"Ado's Utattemita Album\", 'List of Japanese people']\n",
      "\u001b[0m\u001b[1;3;32m> Prompt input to the LLM: \n",
      "\u001b[0m\u001b[1;3;32mRole: user\n",
      "Content: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: search_info_from_wikipedia\n",
      "Tool Description: search_info_from_wikipedia(prompt: str) -> list[str]\n",
      "\n",
      "    Do a wikipedia search for provided `prompt`\n",
      "    Returns a list of ten wikipedia titles that matches the prompt\n",
      "    \n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"prompt\": {\"title\": \"Prompt\", \"type\": \"string\"}}, \"required\": [\"prompt\"]}\n",
      "\n",
      "> Tool Name: get_wikipedia_content_from_title\n",
      "Tool Description: get_wikipedia_content_from_title(title: str) -> str\n",
      " Functions returns content of wikipedia page based on provided title \n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"title\": {\"title\": \"Title\", \"type\": \"string\"}}, \"required\": [\"title\"]}\n",
      "\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of search_info_from_wikipedia, get_wikipedia_content_from_title) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "Role: user\n",
      "Content: **Who is the Japanese singer Yuuri?\n",
      "Role: model\n",
      "Content: Thought: The current language of the user is: english. I need to use a tool to help me answer the question.\n",
      "Action: search_info_from_wikipedia\n",
      "Action Input: {'prompt': 'Japanese singer Yuuri'}\n",
      "Role: user\n",
      "Content: Observation: ['Yuuri (singer-songwriter)', 'Yuri (Japanese name)', 'List of Japanese singers', 'Yuuri Morishita', 'Ayane (singer)', 'Bansanka', 'Japanese people in South Korea', 'The First Take', \"Ado's Utattemita Album\", 'List of Japanese people']\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The current language of the user is: english. I need to use a tool to help me answer the question.\n",
      "Action: get_wikipedia_content_from_title\n",
      "Action Input: {'title': 'Yuuri (singer-songwriter)'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Yuuri (優里, born March 23, 1994) is a Japanese singer-songwriter. He is currently signed under the record label Ariola Japan.\n",
      "\n",
      "\n",
      "== Career ==\n",
      "He began his singing career as a vocalist for the four-man rock band, The Bugzy, until they disbanded in May 2019. After the group's disbandment, he began performing live on the streets of Tokyo. On October 10, 2019, Yuuri was singing [「花 」-0714-] by My First Story on the street at the scrambled intersection in Shibuya. It became a hot topic when My First Story vocalist Hiro, jumped in and sang the second verse of the song with him. After this incident, Yuuri was called out from the crowd to perform spontaneously for the encore final performance on November 30 when My First Story was holding a concert in Saitama Super Arena as a part of their country-wide tour \"My First Story Tour 2019.\" Yuuri's originally composed \"Kakurenbo\" whose recording was supervised by Hiro and My First Story's [「花」 -0714-] were performed together. On December 1, Yuuri released \"Kakurenbo\" independently. It ranked in 4th place on the general chart on iTunes Japan, and the music video garnered over 40 million views. On the same day, MY FIRST STORY'S version of \"Kakurenbo\" was also released.\n",
      "On February 28, 2020, he released his second independent song, titled \"Kagome\", which later topped the USEN indies chart on March 18. He made his official debut with Sony Music on August 9 with his single \"Peter Pan\". On October 25, his second major single, \"Dry Flower\" was released.\n",
      "On February 1, 2021 \"Dry Flower\" exceeded over 100 million streams on the Streaming Songs chart on Billboard Japan. He achieved this number after charting for 13 weeks, becoming the first solo male artist to achieve this, and overall third artist to achieve this following LiSA's \"Homura\" which broke the record after 7 weeks of charting, and BTS' \"Dynamite\" which took 11 weeks. On March 22, 2021, \"Kakurenbo\" also exceeded over 100 million streams on Billboard Japan’s Streaming Songs chart. It is the first time in Billboard Japan history for an artist to have two songs exceed 100 million streams only 8 months after their major debut.\n",
      "On September 1, 2021, \"Dry Flower\" exceeded 400 million streams on Billboard Japan’s Streaming Songs chart. Since it exceeded 400 million streams within 44 weeks of charting, Yuuri became the first and fastest solo male artist to achieve this record, and the second artist overall following BTS’ \"Dynamite.\" He also became the first Japanese artist and solo male artist to exceed 500 million streams on December 22, 2021.\n",
      "His first studio album Ichi was released on January 12, 2022. He also released his first non-Japanese single, the English version of \"Dry Flower\" called \"Dried Flowers\" on January 31, 2022.\n",
      "\n",
      "\n",
      "== Personal life ==\n",
      "When Yuuri was in elementary school, he was influenced by his mother who listened to Western rock music, so he often listened to artists such as Bon Jovi, Queen, and AC/DC. Bon Jovi inspired him to become a singer and pursue music as a career. When he entered high school, he started listening to Japanese artists such as Bump of Chicken and Spitz. He started his Youtube channel 「Yuuri Channel Official 」in March 2020. Since its inception, the channel has garnered over 217 million views and gained over 1 million subscribers. There are 4 main members that create and participate in the channel's content including Yuuri. The other three members are Jun, Genta, and Nari. The contents of the channel range from song covers performed by Yuuri, to karaoke challenges with other guests, and other various contents relating to music, and a new video is uploaded daily.\n",
      "\n",
      "\n",
      "== Discography ==\n",
      "\n",
      "\n",
      "=== Studio albums ===\n",
      "\n",
      "\n",
      "=== Singles ===\n",
      "\n",
      "\n",
      "==== As lead artist ====\n",
      "\n",
      "\n",
      "==== As featured artist ====\n",
      "\n",
      "\n",
      "=== Productions ===\n",
      "April 30, 2021 – Jun Miyasaka \"Shutter\": Lyrics and composition by Yuuri.\n",
      "December 24, 2021 – Junta \"Waraeyo\": Lyrics co-written by Yuuri and CHIMERAZ. Composition by Yuuri.\n",
      "March 23, 2022 – BAK \"Time Machine\": Lyrics and composition by Yuuri.\n",
      "April 20, 2022 – Little Glee Monster 「心に空を」(The sky inside my heart)\n",
      "April 28, 2022 – Ai Tomioka \"Rapunzel\": Lyrics and composition by Yuuri.\n",
      "May 26, 2022 – Maruri \"Sukidayo\": Lyrics and composition by Yuuri.\n",
      "August 24, 2022 – Hey! Say! JUMP \"Bitter Chocolate\": Lyrics and composition by Yuuri.\n",
      "July 1, 2023 – Tomorrow X Together (TXT) \"Hydrangea Love\": Producer, Lyrics and composition by Yuuri.\n",
      "\n",
      "\n",
      "== Appearances ==\n",
      "\n",
      "\n",
      "=== Radio ===\n",
      "October 7, 2020 – Midnight Kakurenbo on FM Yokohama.\n",
      "\n",
      "\n",
      "=== THE FIRST TAKE ===\n",
      "Premiered July 10, 2020 – \"Kakurenbo\" THE HOME TAKE\n",
      "Premiered October 30, 2020 – \"Dry Flower\" THE FIRST TAKE\n",
      "Premiered October 1, 2021 – \"Shutter\" THE FIRST TAKE\n",
      "Premiered October 13, 2021 – \"BETELGEUSE\" THE FIRST TAKE\n",
      "Premiered August 19, 2022 – \"Leo\" THE FIRST TAKE\n",
      "Premiered August 31, 2022 – \"Tag\" THE FIRST TAKE\n",
      "\n",
      "\n",
      "== Music videos ==\n",
      "\n",
      "\n",
      "== Awards and nominations ==\n",
      "\n",
      "\n",
      "== References ==\n",
      "\n",
      "\n",
      "== External links ==\n",
      "Yuuri Official Website\n",
      "Yuuri – Sony Music Official Site JP\n",
      "Yuuri Official Goods Store – official-goods-store.jp\n",
      "Yuuri – Ariola Japan\n",
      "Yuuri on X\n",
      "Yuuri Staff on X\n",
      "Yuuri on Instagram\n",
      "Yuuri on TikTok\n",
      "Yuuri's Official Youtube's channel on YouTube\n",
      "Yuuri Channel Official's channel on YouTube\n",
      "\u001b[0m\u001b[1;3;32m> Prompt input to the LLM: \n",
      "\u001b[0m\u001b[1;3;32mRole: user\n",
      "Content: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: search_info_from_wikipedia\n",
      "Tool Description: search_info_from_wikipedia(prompt: str) -> list[str]\n",
      "\n",
      "    Do a wikipedia search for provided `prompt`\n",
      "    Returns a list of ten wikipedia titles that matches the prompt\n",
      "    \n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"prompt\": {\"title\": \"Prompt\", \"type\": \"string\"}}, \"required\": [\"prompt\"]}\n",
      "\n",
      "> Tool Name: get_wikipedia_content_from_title\n",
      "Tool Description: get_wikipedia_content_from_title(title: str) -> str\n",
      " Functions returns content of wikipedia page based on provided title \n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"title\": {\"title\": \"Title\", \"type\": \"string\"}}, \"required\": [\"title\"]}\n",
      "\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of search_info_from_wikipedia, get_wikipedia_content_from_title) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "Role: user\n",
      "Content: **Who is the Japanese singer Yuuri?\n",
      "Role: model\n",
      "Content: Thought: The current language of the user is: english. I need to use a tool to help me answer the question.\n",
      "Action: search_info_from_wikipedia\n",
      "Action Input: {'prompt': 'Japanese singer Yuuri'}\n",
      "Role: user\n",
      "Content: Observation: ['Yuuri (singer-songwriter)', 'Yuri (Japanese name)', 'List of Japanese singers', 'Yuuri Morishita', 'Ayane (singer)', 'Bansanka', 'Japanese people in South Korea', 'The First Take', \"Ado's Utattemita Album\", 'List of Japanese people']\n",
      "Role: model\n",
      "Content: Thought: The current language of the user is: english. I need to use a tool to help me answer the question.\n",
      "Action: get_wikipedia_content_from_title\n",
      "Action Input: {'title': 'Yuuri (singer-songwriter)'}\n",
      "Role: user\n",
      "Content: Observation: Yuuri (優里, born March 23, 1994) is a Japanese singer-songwriter. He is currently signed under the record label Ariola Japan.\n",
      "\n",
      "\n",
      "== Career ==\n",
      "He began his singing career as a vocalist for the four-man rock band, The Bugzy, until they disbanded in May 2019. After the group's disbandment, he began performing live on the streets of Tokyo. On October 10, 2019, Yuuri was singing [「花 」-0714-] by My First Story on the street at the scrambled intersection in Shibuya. It became a hot topic when My First Story vocalist Hiro, jumped in and sang the second verse of the song with him. After this incident, Yuuri was called out from the crowd to perform spontaneously for the encore final performance on November 30 when My First Story was holding a concert in Saitama Super Arena as a part of their country-wide tour \"My First Story Tour 2019.\" Yuuri's originally composed \"Kakurenbo\" whose recording was supervised by Hiro and My First Story's [「花」 -0714-] were performed together. On December 1, Yuuri released \"Kakurenbo\" independently. It ranked in 4th place on the general chart on iTunes Japan, and the music video garnered over 40 million views. On the same day, MY FIRST STORY'S version of \"Kakurenbo\" was also released.\n",
      "On February 28, 2020, he released his second independent song, titled \"Kagome\", which later topped the USEN indies chart on March 18. He made his official debut with Sony Music on August 9 with his single \"Peter Pan\". On October 25, his second major single, \"Dry Flower\" was released.\n",
      "On February 1, 2021 \"Dry Flower\" exceeded over 100 million streams on the Streaming Songs chart on Billboard Japan. He achieved this number after charting for 13 weeks, becoming the first solo male artist to achieve this, and overall third artist to achieve this following LiSA's \"Homura\" which broke the record after 7 weeks of charting, and BTS' \"Dynamite\" which took 11 weeks. On March 22, 2021, \"Kakurenbo\" also exceeded over 100 million streams on Billboard Japan’s Streaming Songs chart. It is the first time in Billboard Japan history for an artist to have two songs exceed 100 million streams only 8 months after their major debut.\n",
      "On September 1, 2021, \"Dry Flower\" exceeded 400 million streams on Billboard Japan’s Streaming Songs chart. Since it exceeded 400 million streams within 44 weeks of charting, Yuuri became the first and fastest solo male artist to achieve this record, and the second artist overall following BTS’ \"Dynamite.\" He also became the first Japanese artist and solo male artist to exceed 500 million streams on December 22, 2021.\n",
      "His first studio album Ichi was released on January 12, 2022. He also released his first non-Japanese single, the English version of \"Dry Flower\" called \"Dried Flowers\" on January 31, 2022.\n",
      "\n",
      "\n",
      "== Personal life ==\n",
      "When Yuuri was in elementary school, he was influenced by his mother who listened to Western rock music, so he often listened to artists such as Bon Jovi, Queen, and AC/DC. Bon Jovi inspired him to become a singer and pursue music as a career. When he entered high school, he started listening to Japanese artists such as Bump of Chicken and Spitz. He started his Youtube channel 「Yuuri Channel Official 」in March 2020. Since its inception, the channel has garnered over 217 million views and gained over 1 million subscribers. There are 4 main members that create and participate in the channel's content including Yuuri. The other three members are Jun, Genta, and Nari. The contents of the channel range from song covers performed by Yuuri, to karaoke challenges with other guests, and other various contents relating to music, and a new video is uploaded daily.\n",
      "\n",
      "\n",
      "== Discography ==\n",
      "\n",
      "\n",
      "=== Studio albums ===\n",
      "\n",
      "\n",
      "=== Singles ===\n",
      "\n",
      "\n",
      "==== As lead artist ====\n",
      "\n",
      "\n",
      "==== As featured artist ====\n",
      "\n",
      "\n",
      "=== Productions ===\n",
      "April 30, 2021 – Jun Miyasaka \"Shutter\": Lyrics and composition by Yuuri.\n",
      "December 24, 2021 – Junta \"Waraeyo\": Lyrics co-written by Yuuri and CHIMERAZ. Composition by Yuuri.\n",
      "March 23, 2022 – BAK \"Time Machine\": Lyrics and composition by Yuuri.\n",
      "April 20, 2022 – Little Glee Monster 「心に空を」(The sky inside my heart)\n",
      "April 28, 2022 – Ai Tomioka \"Rapunzel\": Lyrics and composition by Yuuri.\n",
      "May 26, 2022 – Maruri \"Sukidayo\": Lyrics and composition by Yuuri.\n",
      "August 24, 2022 – Hey! Say! JUMP \"Bitter Chocolate\": Lyrics and composition by Yuuri.\n",
      "July 1, 2023 – Tomorrow X Together (TXT) \"Hydrangea Love\": Producer, Lyrics and composition by Yuuri.\n",
      "\n",
      "\n",
      "== Appearances ==\n",
      "\n",
      "\n",
      "=== Radio ===\n",
      "October 7, 2020 – Midnight Kakurenbo on FM Yokohama.\n",
      "\n",
      "\n",
      "=== THE FIRST TAKE ===\n",
      "Premiered July 10, 2020 – \"Kakurenbo\" THE HOME TAKE\n",
      "Premiered October 30, 2020 – \"Dry Flower\" THE FIRST TAKE\n",
      "Premiered October 1, 2021 – \"Shutter\" THE FIRST TAKE\n",
      "Premiered October 13, 2021 – \"BETELGEUSE\" THE FIRST TAKE\n",
      "Premiered August 19, 2022 – \"Leo\" THE FIRST TAKE\n",
      "Premiered August 31, 2022 – \"Tag\" THE FIRST TAKE\n",
      "\n",
      "\n",
      "== Music videos ==\n",
      "\n",
      "\n",
      "== Awards and nominations ==\n",
      "\n",
      "\n",
      "== References ==\n",
      "\n",
      "\n",
      "== External links ==\n",
      "Yuuri Official Website\n",
      "Yuuri – Sony Music Official Site JP\n",
      "Yuuri Official Goods Store – official-goods-store.jp\n",
      "Yuuri – Ariola Japan\n",
      "Yuuri on X\n",
      "Yuuri Staff on X\n",
      "Yuuri on Instagram\n",
      "Yuuri on TikTok\n",
      "Yuuri's Official Youtube's channel on YouTube\n",
      "Yuuri Channel Official's channel on YouTube\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Yuuri is a Japanese singer-songwriter who is currently signed under the record label Ariola Japan. He began his singing career as a vocalist for the four-man rock band, The Bugzy, until they disbanded in May 2019. After the group's disbandment, he began performing live on the streets of Tokyo. He made his official debut with Sony Music on August 9 with his single \"Peter Pan\".\n",
      "\u001b[0m('Yuuri is a Japanese singer-songwriter who is currently signed under the '\n",
      " 'record label Ariola Japan. He began his singing career as a vocalist for the '\n",
      " 'four-man rock band, The Bugzy, until they disbanded in May 2019. After the '\n",
      " \"group's disbandment, he began performing live on the streets of Tokyo. He \"\n",
      " 'made his official debut with Sony Music on August 9 with his single \"Peter '\n",
      " 'Pan\".')\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Who is the Japanese singer Yuuri?\")\n",
    "pprint(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0218d09a-36ad-4fb7-97ed-e00de42affa4",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "095a74d0-67c0-46fa-a9a3-b51bcc4394e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc08ed28-4b89-4cb2-900e-2a9adfa9740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cd8387b-bfbc-4c12-ba63-a7f73159a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = FunctionTool.from_defaults(fn=multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db06a254-ad04-4fa9-85f3-f88148abc3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;32mmultiply(a: int, b: int) -> int\n",
      "Multiply two integers and returns the result integer\u001b[0m"
     ]
    }
   ],
   "source": [
    "print_text(tool.metadata.description, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2710533-2015-4c2f-87c7-fe9ea69f9d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;32mmultiply\u001b[0m"
     ]
    }
   ],
   "source": [
    "print_text(tool.metadata.name, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82adfb39-561b-4e96-bf87-f59715a1f60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;32m{'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}\u001b[0m"
     ]
    }
   ],
   "source": [
    "print_text(tool.metadata.get_parameters_dict(), color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93762dda-f3ac-48d5-9d0a-8c145077824d",
   "metadata": {},
   "source": [
    "# ReAct system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5337b3f-1c90-4abc-b7aa-70861d286f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.modules.agents.prompt_formatter import REACT_CHAT_SYSTEM_HEADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59232717-5645-471e-b18b-779c31c31cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "{tool_desc}\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of {tool_names}) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n"
     ]
    }
   ],
   "source": [
    "print_text(REACT_CHAT_SYSTEM_HEADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e0e4c-4f1c-4cc2-8bda-8e0c6f15e2b1",
   "metadata": {},
   "source": [
    "# ReAct Agent Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653cc5a2-9c6a-447f-9b69-c72131760ffe",
   "metadata": {},
   "source": [
    "## Setup new Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec5deded-5801-4b54-84ed-1fa417e31176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.modules.agents import GeminiReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a1d12e7-d906-46b3-97e2-2246d78de1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleLLM(api_key=settings.google_ai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bbdb54e-9b66-4c0f-ac90-076b5c1d047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = GeminiReAct.from_tools([tool], llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad77261-7d1b-4848-b161-e07e347fae09",
   "metadata": {},
   "source": [
    "## Get tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "892b497f-d9cc-401d-9188-88c0cd434732",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = agent.create_task(\"What is 2*8?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04b93260-c1f4-4859-8edd-51a726b71916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task(task_id='e4a83afb-834e-4bb9-8971-9984aecd9278', input='What is 2*8?', memory=ChatMemoryBuffer(token_limit=23040, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatStore(store={'chat_history': []}), chat_store_key='chat_history'), callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000210615F0A00>, extra_state={'sources': [], 'current_reasoning': [], 'new_memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatStore(store={}), chat_store_key='chat_history')})\n"
     ]
    }
   ],
   "source": [
    "pprint(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f262059-33d2-431f-9683-aa515f22e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_queue = agent.state.get_step_queue(task.task_id)\n",
    "step = step_queue.popleft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef2d8b37-fb4f-4852-b0a7-b8b68c5755ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskStep(task_id='e4a83afb-834e-4bb9-8971-9984aecd9278', step_id='8024648b-cd03-45ac-b5e9-b39d6e682a66', input='What is 2*8?', step_state={'is_first': True}, next_steps={}, prev_steps={}, is_ready=True)\n"
     ]
    }
   ],
   "source": [
    "pprint(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfae895-cc1e-4c7e-93e4-292ef381b9da",
   "metadata": {},
   "source": [
    "## Get tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ef5621d-0aca-44c5-a0f6-d2feca77fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = agent.agent_worker.get_tools(task.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be4d0bb1-f4f0-4710-b153-4ec7f74629ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<llama_index.core.tools.function_tool.FunctionTool object at 0x00000210615F3DF0>]\n"
     ]
    }
   ],
   "source": [
    "pprint(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3625fc5-f4ef-4783-9e7c-2809875c5071",
   "metadata": {},
   "source": [
    "## Modify task and prompt according to step input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0fedfa8-89dc-4010-8dfc-f8015945df62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is 2*8?"
     ]
    }
   ],
   "source": [
    "print_text(step.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27468f4e-b923-48dc-9540-811a569af5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.react.step import add_user_step_to_reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdee1bfc-f777-4f7f-b184-1686c7254125",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_user_step_to_reasoning(\n",
    "    step=step,\n",
    "    memory=task.extra_state[\"new_memory\"],\n",
    "    current_reasoning=task.extra_state[\"current_reasoning\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "209c18b6-87c6-4508-81ae-ab9df8b0ca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_limit=3000 tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all') chat_store=SimpleChatStore(store={'chat_history': [ChatMessage(role=<MessageRole.USER: 'user'>, content='What is 2*8?', additional_kwargs={})]}) chat_store_key='chat_history'"
     ]
    }
   ],
   "source": [
    "print_text(task.extra_state[\"new_memory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2776bb0e-32b9-4ab8-a2c7-1171657af64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chat = agent.agent_worker._react_chat_formatter.format(\n",
    "    tools,\n",
    "    chat_history=task.memory.get() + task.extra_state[\"new_memory\"].get_all(),\n",
    "    current_reasoning=task.extra_state[\"current_reasoning\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc6a9433-b45f-43d3-a5e9-ccf394eed6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;31muser: \u001b[0m\u001b[1;3;32mYou are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: multiply\n",
      "Tool Description: multiply(a: int, b: int) -> int\n",
      "Multiply two integers and returns the result integer\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"a\": {\"title\": \"A\", \"type\": \"integer\"}, \"b\": {\"title\": \"B\", \"type\": \"integer\"}}, \"required\": [\"a\", \"b\"]}\n",
      "\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of multiply) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\u001b[0m\u001b[1;3;31muser: \u001b[0m\u001b[1;3;32m**\u001b[0m"
     ]
    }
   ],
   "source": [
    "for chat in input_chat:\n",
    "    print_text(chat[\"role\"] + ': ', color='red')\n",
    "    print_text(chat[\"parts\"][0], color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4e8df-233b-4684-b2a7-7f12f018d8ed",
   "metadata": {},
   "source": [
    "## Get response from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec171a6a-bf09-4d6b-9e84-b69077eda8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = agent.agent_worker._llm.complete(input_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91726bd3-062a-4ad9-999e-b94b39f17ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the chat_response\n",
    "from llama_index.core.base.llms.types import ChatResponse, ChatMessage, MessageRole\n",
    "chat_response = ChatResponse(\n",
    "    message=ChatMessage(\n",
    "        content=chat_response.text\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7c80632-dc32-44f5-a7a4-4a9147f4ad65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;31mLLM: \u001b[0m\u001b[1;3;32mThought: The current language of the user is: english. I need to use a tool to help me answer the question.\n",
      "Action: multiply\n",
      "Action Input: {\"a\": 2, \"b\": 8}\u001b[0m"
     ]
    }
   ],
   "source": [
    "print_text(\"LLM: \", color='red')\n",
    "print_text(f\"{str(chat_response.message.content)}\", color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fee386-2d65-49ba-a501-40b964766479",
   "metadata": {},
   "source": [
    "## How function calling works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e82cd309-d0d1-4347-a350-830dd66fcfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, current_reasoning, is_done = agent.agent_worker._extract_reasoning_step(chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b720427-e138-441e-8d4d-47dcf4b89275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActionReasoningStep(thought='The current language of the user is: english. I need to use a tool to help me answer the question.', action='multiply', action_input={'a': 2, 'b': 8})\n"
     ]
    }
   ],
   "source": [
    "pprint(current_reasoning[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71239829-f0a1-495e-b4f5-5549597aa8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.react.types import ActionReasoningStep\n",
    "from typing import cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a1db2c9-4d88-42e6-a278-5277e7e8a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_step = cast(ActionReasoningStep, current_reasoning[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fceb4be4-f1e6-4320-8a84-ffcc5bd7e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActionReasoningStep(thought='The current language of the user is: english. I need to use a tool to help me answer the question.', action='multiply', action_input={'a': 2, 'b': 8})\n"
     ]
    }
   ],
   "source": [
    "pprint(reasoning_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84762659-e26c-4dcb-a43b-912e00997782",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_dict = {\n",
    "    tool.metadata.get_name(): tool for tool in tools\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5e31951-f872-47ba-b7a6-5c5d38ed3bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'multiply': <llama_index.core.tools.function_tool.FunctionTool object at 0x00000210615F3DF0>}\n"
     ]
    }
   ],
   "source": [
    "pprint(tool_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58fb8a67-3e87-434a-901b-357958c5696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_output = tool_dict[reasoning_step.action].call(**reasoning_step.action_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ffe0852-8886-4bc2-b1b0-a7724f5ef129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolOutput(content='16', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 2, 'b': 8}}, raw_output=16, is_error=False)\n"
     ]
    }
   ],
   "source": [
    "pprint(tool_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea580c-6df2-40ca-9ea6-696fda8b4b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
